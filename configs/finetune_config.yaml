# Fine-tuning pipeline configuration

dataset:
  qa_file: "data/qna/qa_pairs.json"
  qa_instructions_sft : "data/qna/qa_instructions_sft.json"
  train_split: 0.8
  validation_split: 0.1
  test_split: 0.1

model:
  base_model: "distilgpt2"
  save_path: "models/finetuned/"
  device: "cuda"

training:
  epochs: 5
  batch_size: 16
  learning_rate: 5e-5
  optimizer: "adamw"
  warmup_steps: 100
  weight_decay: 0.01

instruction_ft:
  enabled: true
  format: "instruction"        # Use instruction-style prompts

guardrails:
  input_validation: true
  output_filtering: true

logging:
  log_interval: 50             # Log training metrics every N steps

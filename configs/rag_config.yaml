# Retrieval-Augmented Generation (RAG) pipeline configuration

preprocessing:
  chunk_sizes: [100, 400]      # Token chunk sizes for retrieval
  overlap: 20                  # Token overlap between chunks
  lower_case: true
  remove_stopwords: true

embedding:
  model_name: 'intfloat/e5-small-v2' #TODO "sentence-transformers/all-MiniLM-L6-v2"
  embedding_dim: 384
  device: "cpu"               # Options: cuda, cpu

indexing:
  dense_store: "faiss"         # Options: faiss, chromadb
  sparse_store: "bm25"         # Options: bm25, tfidf
  top_k_dense: 5
  top_k_sparse: 5

retrieval:
  fusion_method: "weighted"    # Options: union, weighted
  fusion_weight_dense: 0.6
  fusion_weight_sparse: 0.4

reranker:
  enabled: true
  model_name: "cross-encoder/ms-marco-MiniLM-L-6-v2"
  top_k: 3

generator:
  model_name: "distilgpt2"
  max_input_tokens: 1024
  max_output_tokens: 128

guardrails:
  input_validation: true       # Enable query validation
  output_filtering: true       # Enable hallucination checks

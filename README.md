# Financial QA System: RAG vs Fine-Tuning Comparison

A comprehensive comparison between Retrieval-Augmented Generation (RAG) and Fine-Tuning approaches for financial question-answering systems.

## ğŸ¯ Objective

Develop and compare two systems for answering questions based on company financial statements:
- **RAG Chatbot**: Combines document retrieval and generative response
- **Fine-Tuned Model**: Directly fine-tunes a language model on financial Q&A data

## ğŸ—ï¸ Project Structure

```
financial_qa_system/
â”‚
â”œâ”€â”€ configs/                     # Centralized configs (no hardcoding)
â”‚   â”œâ”€â”€ app_config.yaml          # Global settings (paths, logging level, etc.)
â”‚   â”œâ”€â”€ gaurdrail_config.yaml    # invalid words etc
â”‚   â”œâ”€â”€ rag_config.yaml          # RAG-specific configs
â”‚   â””â”€â”€ finetune_config.yaml     # Fine-tuning configs
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Original raw data (PDFs, JSON Q&A)
â”‚   â”‚   â”œâ”€â”€ amazon_2023.pdf
â”‚   â”‚   â”œâ”€â”€ amazon_2024.pdf
â”‚   â”‚   â””â”€â”€ qa_pairs.json
â”‚   â”œâ”€â”€ qa/                      # qa created for fine tuning
â”‚   â”œâ”€â”€ processed/               # Processed data (cleaned text)
â”‚   â”œâ”€â”€ chunks/                  # chunks from processed text
â”‚   â””â”€â”€ embeddings/              # Vector stores (FAISS, ChromaDB)
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ system.log               # Consolidated logs
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ rag/                     # Saved RAG pipeline models
â”‚   â””â”€â”€ finetuned/               # Saved fine-tuned models
â”‚
â”œâ”€â”€ notebooks/                   # Exploration notebooks
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                   # Utility functions (shared)
â”‚   â”‚   â”œâ”€â”€ logger.py            # Logging setup
â”‚   â”‚   â”œâ”€â”€ config_loader.py     # Load YAML configs
â”‚   â”‚   â””â”€â”€ evaluation.py        # Evaluation metrics
â”‚   â”‚
â”‚   â”œâ”€â”€ data_processing/         # All data-related processing
â”‚   â”‚   â”œâ”€â”€ preprocess.py        # Cleaning, text extraction
â”‚   â”‚   â”œâ”€â”€ chunking.py          # Split into chunks
â”‚   â”‚   â””â”€â”€ dataset_prep.py      # Prepare Q&A dataset for FT
â”‚   â”‚
â”‚   â”œâ”€â”€ llm_pipeline/            # common classes required for RAG and FineTuning
â”‚   â”‚   â”œâ”€â”€ base_qa_system.py    # Base class for RAGPipeline and FineTunePineline
â”‚   â”‚   â””â”€â”€ guardrails.py        # Input and output guardrail implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ rag_pipeline/            # Retrieval-Augmented Generation modules
â”‚   â”‚   â”œâ”€â”€ pipeline.py          # RAG pipeline setup, safe_answer
â”‚   â”‚   â”œâ”€â”€ embed_index.py       # Build & store dense + sparse indices
â”‚   â”‚   â”œâ”€â”€ retrieval.py         # Hybrid retrieval logic
â”‚   â”‚   â”œâ”€â”€ reranker.py          # Multi-stage retrieval re-ranking
â”‚   â”‚   â””â”€â”€ generator.py         # RResponse generation module
â”‚   â”‚
â”‚   â”œâ”€â”€ finetune_pipeline/       # Fine-tuning modules
â”‚   â”‚   â”œâ”€â”€ baseline_eval.py     # Pre-fine-tuning benchmarking
â”‚   â”‚   â”œâ”€â”€ trainer.py           # Fine-tuning loop
â”‚   â”‚   â”œâ”€â”€ instruction_ft.py    # Supervised Instruction Fine-tuning
â”‚   â”‚   â””â”€â”€ guardrails.py        # Fine-tuning guardrail
â”‚   â”‚
â”‚   â”œâ”€â”€ interface/               # Frontend/UI
â”‚   â”‚   â”œâ”€â”€ app.py               # Streamlit/Gradio entry point
â”‚   â”‚   â””â”€â”€ components.py        # UI components (switch modes, display confidence, etc.)
â”‚   â”‚
â”‚   â””â”€â”€ deployment/              # Model & pipeline loading for inference
â”‚       â”œâ”€â”€ load_model.py        # Load saved fine-tuned model
â”‚       â””â”€â”€ load_rag.py          # Load vector store & generation pipeline
â”‚
â””â”€â”€ tests/
    â”œâ”€â”€ test_rag.py              # Unit tests for RAG modules
    â”œâ”€â”€ test_finetune.py         # Unit tests for fine-tuning
    â””â”€â”€ test_interface.py        # UI and integration tests


```

## ğŸš€ Quick Start

1. **Setup Environment**
   ```bash
   git clone <repository-url>
   cd financial_qa_system
   pip install -r requirements.txt
   ```

2. **Prepare Data**
   - Place your financial reports in `data/raw/`
   - Ensure Q&A pairs are in `data/qa/qa_pairs.json`

3. **Configure System**
   ```bash
   cp .env.example .env
   # Edit .env and config files as needed
   ```

4. **Run Setup**
   ```bash
   python scripts/setup_environment.py
   ```

5. **Launch Interface**
   ```bash
   streamlit run src/interface/streamlit_app.py
   ```

## ğŸ“Š Features

### RAG System
- **Multi-stage Retrieval**: Dense + Sparse hybrid retrieval with re-ranking
- **Flexible Chunking**: Multiple chunk sizes (100, 400 tokens)
- **Advanced Indexing**: FAISS vector store + BM25 sparse index
- **Guardrails**: Input validation and output filtering

### Fine-Tuning System  
- **Supervised Instruction Fine-Tuning**: Custom Q&A training
- **Efficient Training**: Gradient accumulation and learning rate scheduling
- **Model Checkpointing**: Resume training and model versioning
- **Baseline Benchmarking**: Pre/post fine-tuning comparison

### Evaluation Framework
- **Comprehensive Metrics**: Accuracy, speed, confidence scoring
- **Robustness Testing**: Relevant, irrelevant, and edge-case questions  
- **Statistical Analysis**: Detailed performance comparison
- **Visualization**: Interactive results dashboard

## ğŸ”§ Configuration

Key configuration files:
- `config/config.yaml` - Main system configuration
- `config/rag_config.yaml` - RAG-specific settings
- `config/finetuning_config.yaml` - Fine-tuning parameters
- `config/logging_config.yaml` - Logging configuration

## ğŸ“ˆ Usage Examples

### Programmatic Usage
```python
from src.rag_system.rag_pipeline import RAGPipeline
from src.finetuning_system.finetuning_pipeline import FineTuningPipeline

# Initialize systems
rag_system = RAGPipeline(config)
ft_system = FineTuningPipeline(config)

# Ask questions
rag_answer = rag_system.answer_question("What was Amazon's revenue in 2023?")
ft_answer = ft_system.answer_question("What was Amazon's revenue in 2023?")
```

### Command Line Interface
```bash
# Run evaluation
python scripts/run_evaluation.py --config config/config.yaml

# Train fine-tuned model
python scripts/train_finetuned_model.py --epochs 5 --lr 5e-5
```

## ğŸ§ª Testing

Run the test suite:
```bash
pytest tests/ -v --cov=src
```

## ğŸ“ Results

Results are automatically saved to:
- `results/rag_results/` - RAG system performance
- `results/finetuning_results/` - Fine-tuning performance  
- `results/comparison_results/` - Comparative analysis
- `results/reports/` - Generated reports

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests and ensure code quality
5. Submit a pull request

## ğŸ“„ License


## ğŸ”— References

- [RAG Paper](https://arxiv.org/abs/2005.11401)
- [Fine-tuning Best Practices](https://huggingface.co/docs/transformers/training)
- [Financial NLP Resources](https://github.com/topics/financial-nlp)
